# elastic2python

elastic2python это набор функций, которые позволяют удобно извлечь данные из elastic или opensearch с помощью python и представить их в виде list of dicts или сохранить в csv.
***
Для чего это нужно:
* позволяет работать с данными в pandas
* позволяет выгружать данные в csv
***
Пример использования представлен в файле elastic2python.ipynb
***
Для работы необходимы модули elasticsearch и opensearch-py соответственно.
***
Основные функции, предлагаемые для использования:

### data_taxi -- получаем данные как в Discovery

    elastic_client, # клиент подключения elasticsearch или opensearch-py
    index, # индекс или датавью системы
    query, # DSL запрос, можно отладить и позаимствовать из блока inspect->request в интерфейсе kibana или opensearch
    sort, # параметры сортировки (search_after работает с первым по списку, лучше его оставить единственным), можно отладить и позаимствовать из блока inspect->request в интерфейсе kibana или opensearch 
    fields,  # список выделяемых полей, данные берутся только оттуда, можно отладить и позаимствовать из блока inspect->request в интерфейсе kibana или opensearch
    size, # сколько записей будет запрошено за раз. Обычно это 10000, но для управления нагрузкой на сервер можно выставлять меньше. Главное, чтобы по модулю оно было больше search_after_shift.
    search_after, # первый ограничитель забираемых данных, обычно равен "lte" блоку при сортировке по времени, крайняя минимальная граница диапазона, далее она будет сдвигаться от итерации до итерации, пока не достигнет максимальной.
    search_after_shift, # обратный сдвиг при формировании search_after для следующей итерации. Нужен при высокой плотности событий, когда близко располагаемые документы оказываются с идентичным параметром, указанным в sort. Обеспечивает корректность пагинации. Обычно -10 хватает, главное, чтобы по модулю был меньше size.
    debug = False # параметр для отладки, включает текстовые сообщения.

На выходе будет [{...},{...},...].

### data_taxi_aggs -- получаем данные как в Aggregation Based->Data Table

    elastic_client, # клиент подключения elasticsearch или opensearch-py
    index, # индекс или датавью системы
    query, # DSL запрос, можно отладить и позаимствовать из блока inspect->request в интерфейсе kibana или opensearch 
    aggs, # aggs блок, можно отладить и позаимствовать из блока inspect->request в интерфейсе kibana или opensearch. Это можно найти в Visualize Library->Create Visualization->Aggregation based->Data table->index/dataview.
    debug = False, # параметр для отладки, включает текстовые сообщения .
    size = 0 # Параллельно забираемые данные, функция с ними не работает, поэтому 0.

На выходе будет [{...},{...},...].

### data_taxi_csv_downloader -- получаем данные как в Discovery и сохраняем в csv

    elastic_client, # аналогично data_taxi 
    index, # аналогично data_taxi 
    query, # аналогично data_taxi 
    sort, # аналогично data_taxi  
    fields, # аналогично data_taxi  
    size, # аналогично data_taxi  
    search_after, # аналогично data_taxi  
    search_after_shift, # аналогично data_taxi  
    filename, # в какой файл сохраняем получаемые данные
    writemode # выбор способа записи. "append" -- значит каждую итерацию сразу записываем в файл и тем самым экономим ОЗУ. Потребуется в дальнейшем удалить дубликаты по полю _id. "full" -- значит каждую итерацию пишем в ОЗУ. Дубликаты удалим через pandas сразу.


На выходе будет csv файл.
